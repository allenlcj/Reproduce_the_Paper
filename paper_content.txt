                              This article has been accepted for publication in IEEE Transactions on Network Science and Engineering. This is the author's version which has not been fully edited and
                                                         content may change prior to final publication. Citation information: DOI 10.1109/TNSE.2025.3585287


                                                                                                                                                                                                         1




             APT-SAT: An Adaptive DNN Partitioning and
            Task Offloading Framework within Collaborative
                  Satellite Computing Environments
            Shifeng Peng, Zhishu Shen, Member, IEEE, Qiushi Zheng, Member, IEEE, Xuefeng Hou, Dawen Jiang,
                            Jingling Yuan, Senior Member, IEEE, and Jiong Jin, Member, IEEE

                Abstract—Satellite computing has emerged as a promising technology for next-generation wireless networks, providing various data
                processing capabilities within space networks. This advancement facilitates the widespread implementation of artificial intelligence
                (AI)-driven IoT applications like image processing tasks involving deep neural networks (DNN). However, the constrained
                computational and communication capacities of individual satellites pose significant challenges in efficiently managing DNN tasks
                generated by diverse users. One viable solution involves partitioning DNN tasks into multiple subtasks and distributing them across
                multiple satellites for collaborative computing. Despite its potential, it faces challenges in effectively partitioning DNNs to minimize delay
                and energy consumption while ensuring efficient subtask allocation to maintain load balancing and high task completion rates. To this
                end, we propose an adaptive DNN partitioning and task offloading framework named APT-SAT to enable efficient distributed computing
                among multiple satellites. APT-SAT incorporates an adaptive DNN partitioning algorithm that aims to evenly distribute the workload of
                DNN slices. Furthermore, a routing and task offloading algorithm, leveraging the soft actor-critic (SAC) approach, is introduced to
                optimize offloading decisions. The extensive experiments validate the effectiveness of APT-SAT in terms of task completion rate, delay,
                energy consumption, and resource utilization, highlighting its potential for enabling efficient satellite-based AI applications.

                Index Terms—Collaborative computing, satellite networks, DNN partitioning, task offloading

                                                                                                       ✦


          1    I NTRODUCTION                                                                                   Satellite computing has emerged as a potential technol-
                                                                                                           ogy in addressing the aforementioned issue occurring in re-

          T    HE beyond 5G or 6G (B5G/6G) networks are antici-
               pated to meet the ubiquitous demands of the future
          digital society. Compared to the previous generations of
                                                                                                           mote rural areas. It possesses a unique strength in providing
                                                                                                           global coverage, extending connectivity to areas beyond the
                                                                                                           reach of conventional terrestrial networks [4]–[6]. Leverag-
          communication standards, B5G/6G has the characteristics                                          ing on-board computing capabilities in satellites for various
          of employing large bandwidth, low latency, and wide con-                                         IoT task processing can notably reduce the service delay
          nection, facilitating enhanced mobile broadband and Inter-                                       and energy consumption [7], especially for image processing
          net of Things (IoT) services for a vast number of users [1],                                     tasks involving deep neural network (DNN). Unfortunately,
          [2]. However, the existing base stations (BSs) are unrealistic                                   these DNN tasks are inherently computation-intensive and
          for widespread deployment in remote rural areas, primarily                                       delay/energy-critical inference tasks [8]. As a result, it is
          due to geographical and economic restrictions. Furthermore,                                      challenging to execute these tasks on resource-constrained
          the proliferation of mobile devices and the growing demand                                       satellites with low delay and energy consumption. Parti-
          for smart IoT applications in these areas have given rise to                                     tioning the DNN model into multiple segments, with a
          a surge in computationally intensive IoT-based tasks. In the                                     focus on minimizing transmission costs, can enhance its
          absence of robust ground network infrastructure, processing                                      inference performance [9], [10]. Based on this observation,
          these tasks generated by users or devices in remote rural                                        Chen et al. proposed a practical approach involves par-
          areas becomes a critical issue [3].                                                              titioning DNN computations between satellites to enable
                                                                                                           collaborative satellite computing [11]. In this approach, the
          Shifeng Peng, Zhishu Shen, Xuefeng Hou, Dawen Jiang, and Jingling                                task segments corresponding to DNN slices are offloaded
          Yuan are with the School of Computer Science and Artificial Intelligence,                        to different satellites for collaborative computing. However,
          Wuhan University of Technology, Wuhan, China (e-mail: psf@whut.edu.cn,
                                                                                                           due to the different execution delays, energy consumption,
          z shen@ieee.org, {martinhou, davin, yjl}@whut.edu.cn). Zhishu Shen and
          Jingling Yuan are also with the Hubei Key Laboratory of Transportation                           and intermediate output data sizes of each DNN layer, col-
          Internet of Things, School of Computer Science and Artificial Intelligence,                      laborative computing methods between satellites may lead
          Wuhan University of Technology, Wuhan, China, and China–Chile ICT Belt                           to long-term transmission of massive intermediate data, re-
          and Road Joint Laboratory.
          Qiushi Zheng and Jiong Jin are with the School of Engineering,                                   sulting in unpredictable communication delays and energy
          Swinburne University of Technology, Australia (e-mail: {qiushizheng,                             consumption [12]. Furthermore, to enhance feature repre-
          jiongjin}@swin.edu.au).                                                                          sentation, DNN models frequently incorporate a substantial
          This work was supported in part by the National Natural Science Foundation                       number of layers [13], thereby intensifying the complexity
          of China (Grant No. 62472332) and the Hubei Provincial International
          Science and Technology Cooperation Project (No. 2024EHA031).                                     of DNN partitioning process.
          Corresponding author: Zhishu Shen.                                                                   On the other hand, task offloading schemes are also

Authorized licensed use limited to: NANJING UNIVERSITY OF AERONAUTICS AND ASTRONAUTICS. Downloaded on July 14,2025 at 01:09:40 UTC from IEEE Xplore. Restrictions apply.
                              © 2025 IEEE. All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. Personal use is permitted,
                                                 but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
                             This article has been accepted for publication in IEEE Transactions on Network Science and Engineering. This is the author's version which has not been fully edited and
                                                        content may change prior to final publication. Citation information: DOI 10.1109/TNSE.2025.3585287


                                                                                                                                                                                                        2

          crucial for the efficient processing of DNN tasks on satellite
          networks. Currently, the task offloading scheme predomi-
          nantly employs a centralized architecture [14]. In this archi-
          tecture, a single satellite dictates the offloading locations for
          all tasks [15], which results in substantial communication
          and computational overhead, particularly within large-scale
          low Earth orbit (LEO) satellite networks. Moreover, the cen-
          tralized architecture can lead to unbalanced use of satellite
          resources, resulting in overburdened computing loads on
          certain satellites [16]. To solve this issue, a distributed archi-
                                                                                                                        Fig. 1: Typical DNN partitioning schemes.
          tecture that relies on data sharing among various satellites
          is anticipated. In this architecture, each terminal, such as                                                               TABLE 1
          a satellite, independently determines offloading decisions                                                C OMPARISONS OF DNN PARTITIONING MODELS .
          based on its local observations [17]. Despite these efforts,
          issues with non-convergence arise when striving for global                                          Models                       PTN1              Criteria                     Slice Num.
          optimization. A key inquiry is whether we can enhance                                               DeepThings [18]              Vertical          Memory, cost                 ≥2
                                                                                                              Neurosurgeon [19]            Horizontal        Energy, delay                2
          the optimization of DNN collaborative computing within                                              MoDNN [20]                   Horizontal        Delay                        ≥2
          satellite networks.                                                                                 Cogent [21]                  Horizontal        Accuracy, delay              2
              To this end, we propose APT-SAT, an Adaptive DNN                                                DeepX [22]                   Hybrid            Energy, memory               ≥2
                                                                                                              AOFL [23]                    Hybrid            Latency, cost                ≥2
          Partitioning and Task offloading framework within collab-                                           CRIME [24]                   Hybrid            Energy, delay                ≥2
          orative SATellite computing environments. This framework                                            DeepSlicing [25]             Hybrid            Memory, delay                ≥2
          aims to decrease the delay and energy consumption asso-                                             Edgent [26]                  Hybrid            Accuracy                     2
                                                                                                              This work                    Horizontal        Energy, delay, VW2           ≥2
          ciated with DNN task execution, enhance task completion                                             1
                                                                                                                  PTN: Partitioning scheme
          rate and promote satellite load balancing. Initially, APT-SAT                                       2
                                                                                                                  VW: Variance of workload
          utilizes prediction models to facilitate splitting the DNN
          tasks of varying sizes. These models forecast the delay and
          energy usage of DNN model layers within a simulated                                             Section 2 summarizes the research background and related
          satellite network setting. Subsequently, it identifies the most                                 work and Section 3 describes the problem statement. Sec-
          suitable partitioning points for DNN models based on these                                      tion 4 summarizes the framework we proposed and presents
          predictions and network conditions. The decision satellite                                      our proposed DNN partitioning and task offloading algo-
          then splits the DNN task into segments at these points                                          rithms. Section 5 summarizes the evaluation results that
          and allocates them to multiple satellites for collaborative                                     verify the performance of APT-SAT against that of the
          computing. Based on this framework, we develop an adap-                                         comparable methods. Section 6 concludes this paper.
          tive DNN partitioning algorithm, with the aim of selecting
          multiple partition points to reduce the execution and trans-                                    2        BACKGROUND AND R ELATED W ORK
          mission delay and energy consumption. In addition, we in-
          troduce an algorithm developed from soft actor-critic (SAC)
          approach to explore optimal solutions in a large decision
          space. The primary contributions of this work include:                                          2.1       DNN Partitioning and Task Splitting
                                                                                                          The characteristics of DNN models enable them to be easily
              •   A framework APT-SAT is developed to facilitate
                                                                                                          partitioned and deployed to multiple satellites for collabo-
                  collaborative computing between multiple satellites.
                                                                                                          rative computing. As illustrated in Fig. 1, the partitioning
                  This framework encompasses the prediction stage,
                                                                                                          scheme of the DNN models can be divided into vertical
                  the partitioning stage, and the collaborative comput-
                                                                                                          partitioning, horizontal partitioning, and hybrid (vertical-
                  ing stage, focusing on optimizing task completion
                                                                                                          horizontal) partitioning. By applying these partitioning
                  rate, computation delay and energy consumption.
                                                                                                          schemes to the given DNN model, the original model is
              •   Based on this framework, an adaptive DNN parti-
                                                                                                          divided into interdependent slices of varying granularity.
                  tioning algorithm is developed for identifying opti-
                                                                                                          These slices are then deployed across different devices, such
                  mal multiple partitioning points of the DNN model
                                                                                                          as edge devices and satellites, based on their dependency
                  that meet the requirements of multiple network cri-
                                                                                                          relationships.
                  teria. Moreover, a self-adaptive task offloading al-
                                                                                                              Table 1 summarizes typical models that utilize various
                  gorithm based on SAC is introduced to determine
                                                                                                          DNN partitioning schemes. These models optimize critical
                  the optimal offloading decision in dynamic network
                                                                                                          performance metrics, such as latency, energy consumption,
                  environments.
                                                                                                          and accuracy, by identifying partition points within the
              •   Extensive experiments are conducted on two typi-
                                                                                                          model that best align with the user or system requirements.
                  cal DNN models with different network scales. The
                                                                                                          For example, Li et al. [26] introduced an on-demand deep
                  obtained results highlight the superior performance
                                                                                                          learning model inference framework that operates across
                  of our proposal against other methods in terms of
                                                                                                          devices and edge clouds. It enhances deep learning infer-
                  task completion rate, task delay, and task energy
                                                                                                          ence efficiency through methods like DNN partitioning and
                  consumption.
                                                                                                          DNN rightsizing. Zhang et al. [25] proposed DeepSlicing, a
              The remainder of this paper is organized as follows:                                        technique that supports customized, flexible, fine-grained

Authorized licensed use limited to: NANJING UNIVERSITY OF AERONAUTICS AND ASTRONAUTICS. Downloaded on July 14,2025 at 01:09:40 UTC from IEEE Xplore. Restrictions apply.
                             © 2025 IEEE. All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. Personal use is permitted,
                                                but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
                             This article has been accepted for publication in IEEE Transactions on Network Science and Engineering. This is the author's version which has not been fully edited and
                                                        content may change prior to final publication. Citation information: DOI 10.1109/TNSE.2025.3585287


                                                                                                                                                                                                        3

          partitioning to enable collaborative and adaptive DNN                                           from theoretical exploration to real-world implementation.
          inference. In this approach, both DNN models and data                                           Specifically, the onboard computing addresses the chal-
          are partitioned to balance computation and synchronization                                      lenges of the traditional satellite systems by enabling in-
          effectively. Kim et al. [27] introduced CO-PILOT, a partition                                   orbit data processing and feature extraction, significantly
          framework for collaborative intelligence aiming at reducing                                     reducing the volume of transmitted data. This paradigm not
          end-to-end latency, while maintaining model accuracy. Li et                                     only decreases reliance on ground links but also enhances
          al. [28] investigated distributed DNN inference with fine-                                      transmission efficiency [5], [34]. Beyond mitigating band-
          grained model partitioning to find a competitive model                                          width pressure on satellite-ground links, these advance-
          partitioning policy of per DNN blocks that reduces DNN                                          ments also pave the way for space-based edge comput-
          inference delay. Liao et al. [29] proposed a partition point                                    ing: Cassará et al. evaluated the global service coverage
          retain algorithm to reduce solution space and an optimal                                        performance of LEO satellites functioning as distributed
          partition point algorithm to find the optimal partitioning                                      computing nodes through task offloading mechanisms [35].
          point with the minimum cost for each edge server corre-                                         However, the practical implementation of satellite com-
          sponding to each mobile device. Liang et al. [30] proposed                                      puting faces multiple physical constraints and technical
          a dynamic adaptive DNN surgery scheme, which optimally                                          bottlenecks: (1) The dynamic topology caused by satellites’
          partitions the DNN under different network conditions. It                                       high-speed motion introduces instability in communication
          employs the graph minimum cut algorithm to determine                                            latency [36], and (2) the impact of space radiation on the reli-
          the optimal partition point between the cloud and the edge.                                     ability of commercial off-the-shelf (COTS) components. The
              The partitioning methods utilized in the aforementioned                                     European Space Agency (ESA)’s CloudScout project [37]
          works primarily employ coarse-grained approaches, like                                          reduced in-orbit inference errors in deep learning models
          one-point or two-point partitioning. The fine-grained par-                                      by employing FPGA accelerators and radiation-hardened
          titioning method has not been considered, which is crucial                                      design. Unfortunately, the high hardware costs remain a
          for multi-equipment collaborative computing. On the other                                       challenge for large-scale satellite deployment.
          hand, whether the workload of each block is balanced after                                          Recently developed satellite platforms equipped with
          DNN partitioning has not been considered. Balancing the                                         onboard edge computing capabilities offer significant ad-
          workload of each piece of work can maximize the utilization                                     vantages, including real-time data processing and a reduced
          of resources of the equipment participating in the task                                         volume of data transmission to ground stations. For ex-
          execution. Our proposed framework supports horizontal                                           ample, a research team at Carnegie Mellon University [38]
          partitioning by enabling layer-wise splitting across all types                                  introduced an Onboard Edge Computing (OEC) architecture
          of DNN layers, thereby facilitating fine-grained hierarchical                                   designed for camera-equipped nano-satellites. This architec-
          decomposition and collaborative computing in large-scale                                        ture enables onboard processing of sensed data, including
          satellite networks. In contrast, designing a vertical or hybrid                                 the execution of machine learning and inference algorithms,
          partitioning strategy, where DNN tasks are divided into                                         significantly reducing system latency. In addition, a research
          grid-based subtasks for parallel execution, it is essential to                                  group of Beijing University of Posts and Telecommunica-
          consider the computational overhead in dynamic resource-                                        tions [39] developed an open satellite research platform
          constrained satellite networks.                                                                 named Tiansuan, which provides satellite networks with
                                                                                                          an on-orbit lightweight 5G core and edge computing plat-
                                                                                                          form. By leveraging KubeEdge and its AI extension, this
          2.2   Satellite Computing
                                                                                                          platform facilitates satellite-ground collaborative inference
          Due to the lack of onboard computing capabilities, tradi-                                       applications, achieving up to a 50% improvement in in-
          tional satellite systems have long relied on the bent-pipe ar-                                  orbit image detection accuracy while reducing satellite data
          chitecture, whose fundamental limitation lies in their depen-                                   transmission by 90%.
          dency on ground systems for data processing. As a result,
          current satellite systems primarily serve data collection and
          communication functions. A typical example is the CryoSat-                                      2.3      Task Offloading in Satellite Networks
          2 satellite [31], which conducts precise measurements of                                        As aforementioned, satellite computing is an emerging re-
          Earth’s cryosphere for environmental monitoring. Instead                                        search field and how to make the optimal strategy in a
          of performing advanced processing in orbit, it transmits                                        hierarchical computation offloading architecture is one of
          raw observational data to terrestrial computing infrastruc-                                     the main challenges. Task offloading in satellite networks
          ture for complex analysis. From a theoretical perspective,                                      involves redistributing computational workloads, such as
          Denby et al. [32] demonstrated that as the network scale                                        data processing and AI inference, from resource-constrained
          exceeds thousands of satellites, control command interac-                                       nodes to neighboring nodes within the network. This pro-
          tions and data communication introduce significant latency,                                     cess optimizes network performance by balancing key fac-
          downlink deficits, and energy consumption challenges. Sim-                                      tors such as latency, energy consumption, bandwidth avail-
          ilarly, Bhattacherjee et al. [33] indicated that the reliance                                   ability, and computational capacity.
          on ground station-dependent data processing in traditional                                          Table 2 summarizes the existing task offloading algo-
          satellite systems creates overwhelming bandwidth pressure                                       rithms designed for satellite networks. Among these al-
          on satellite-ground links.                                                                      gorithms, Cheng et al. [40] conducted a joint optimiza-
              With the rapid deployment of LEO satellite constella-                                       tion of computation offloading and power control. They
          tions, satellite computing, an essential technical paradigm                                     introduced a Lyapunov optimization-based algorithm for
          supporting diverse AI-driven tasks, is swiftly transitioning                                    minimizing the overall delay of tasks while satisfying the

Authorized licensed use limited to: NANJING UNIVERSITY OF AERONAUTICS AND ASTRONAUTICS. Downloaded on July 14,2025 at 01:09:40 UTC from IEEE Xplore. Restrictions apply.
                             © 2025 IEEE. All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. Personal use is permitted,
                                                but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
                             This article has been accepted for publication in IEEE Transactions on Network Science and Engineering. This is the author's version which has not been fully edited and
                                                        content may change prior to final publication. Citation information: DOI 10.1109/TNSE.2025.3585287


                                                                                                                                                                                                         4
          TABLE 2
                                                                                                          3.1      System Model
          C OMPARISONS OF TASK OFFLOADING ALGORITHMS .
                                                                                                          In this paper, we consider an integrated satellite-ground sys-
            Ref.          Methods             Energy        Delay        Task drop rate
                                                                                                          tem comprising LEO satellites and user equipments (UEs)
            [40]          Lyapunov              ✓            ✓
            [41]          ADMM                  ✓                                                         distributed across remote rural areas. A network of multiple
            [42]          TTCO                  ✓              ✓                                          LEO satellites is deployed to achieve seamless global cover-
            [43]          LSTM                  ✓              ✓                                          age as shown in Fig. 2. In this satellite network, each satellite
            [44]          MA-DATD3              ✓              ✓
            [45]          MADDPG                ✓                                                         i (∈ S ) orbits the Earth periodically, enabling continuous
            [46]          MAIBJ                 ✓              ✓                                          satellite-ground connections. Due to the limited computa-
            [47]          GA                                   ✓                  ✓                       tional capabilities of UEs, these devices are constrained in
            [48]          DDPG                   ✓             ✓                                          handling resource-intensive tasks. Consequently, the com-
            [49]          DQN                    ✓                                ✓
            This work     SAC                    ✓             ✓                  ✓                       puting tasks need to be offloaded to satellites via gateways
                                                                                                          for processing, with all task transmissions required to pass
                                                                                                          through the gateways in the system [53]. The gateway g (∈
          energy constraints of satellites. Tang et al. [41] transformed                                  G ) in each area is responsible for collecting tasks generated
          the offloading decision optimization problem into a lin-                                        by the UEs within its designated area and transmitting these
          ear programming problem by using the binary variables                                           tasks to the satellite through wireless links. The satellites,
          relaxation method. A distributed algorithm based on the                                         equipped with pre-trained deep neural network (DNN)
          alternating direction method of multipliers (ADMMs) was                                         models, process the received tasks. Moreover, satellite-to-
          proposed to approximate the optimal solution with low                                           satellite communication is facilitated through inter-satellite
          computational complexity. Zhang et al. [50] explored a par-                                     link (ISL). For example, in Fig. 2, Satellite #1 receives tasks
          tial computation offloading strategy to minimize system                                         to be conducted by DNN model 1 from a specific area
          energy consumption, which included joint considerations                                         and executes task splitting. The segmented tasks are then
          of user association, power allocation, task scheduling, and                                     offloaded to Satellite #4 and Satellite #5 through ISL (See
          bandwidth assignment. Peng et al. [47] proposed a task                                          the red arrow in Fig. 2).
          offloading method developed from genetic algorithm (GA)                                              Without loss of generality, we designate the decision-
          that optimizes offloading decisions by analyzing the task                                       making satellite to provide access and computing services to
          inference process for collaborative satellite computing sys-                                    the UEs and gateway g within its covered area. We assume
          tems.                                                                                           the gateway prioritizes satellites within its current coverage
               In recent years, the advancement of deep reinforce-                                        based on orbital dynamics to minimize latency and maintain
          ment learning (DRL) technologies has led to their growing                                       reliable line-of-sight connectivity. The system operational
          adoption in task offloading within satellite networks. Ji et                                    time is divided into Γ discrete time slots of unit length,
          al. [51] proposed a multi-agent double actors twin delayed                                      denoted by τ = {1, 2, ..., Γ}. Hypothetically, the number
          deterministic policy gradient (MA-DATD3) algorithm that                                         of DNN task arrivals within the coverage of the decision-
          contains double actors and double critics. MA-DATD3 is                                          making satellite in each slot t (∈ τ ) follows a Poisson
          designed to solve the computation offloading optimization                                       distribution. Upon receiving the DNN tasks, the decision-
          problem with a centralized training and decentralized exe-                                      making satellite splits them and offloads these segments to
          cution paradigm. Li et al. [52] proposed a multi-agent deep                                     multiple satellites for collaborative computing.
          reinforcement learning algorithm with global rewards to
          optimize the offloading decision via a decentralized method,
          thus achieving the computation offloading and resource                                          3.2      Communication Model
          allocation for the LEO satellite network. Lyu et al. [46]                                       Before the satellite determines task offloading decisions,
          proposed a multi-agent information broadcasting and judg-                                       the tasks must be transmitted to the satellite through the
          ing (MAIBJ) algorithm. With MAIBJ, satellites can decide                                        satellite-ground wireless link. Assuming that multiple gate-
          whether to utilize the received information or not, which en-                                   ways share the available bandwidth without causing in-
          hances the flexibility of offloading decision making. Zhang                                     terference, the average transmission rate vg,i (t) between
          et al. [48] proposed a collaborative computation offload-                                       gateway g and satellite i is determined using the Shannon
          ing scheme based on deep deterministic policy gradient                                          formula as follows:
          (DDPG), with the objective to minimize the system energy
          consumption during long-term task processing in satellite                                                                                                  Pg ξg,i (t)
                                                                                                                                vg,i (t) = B0 log2 (1 +                          ),                     (1)
          edge computing environments. However, these methods                                                                                                          GN
          primarily catered to scenarios with a limited number of
          satellites covering a single area, rendering them unsuitable                                    where B0 is the channel bandwidth, Pg represents the
          for offloading extensive DNN tasks that demand substantial                                      transmit power, ξg,i (t) denotes the channel gain consists of
          computing resources.                                                                            large-scale fading and shadowed-Rician fading [41], and GN
                                                                                                          indicates the additive white Gaussian noise.
                                                                                                              The satellite network consists of No orbits, on which Ns
                                                                                                          satellites are uniformly distributed across these orbits. Due
          3    P ROBLEM S TATEMENT                                                                        to the constraints imposed by communication distances,
                                                                                                          each satellite can only transmit tasks to its adjacent satellites
                                                                                                          through ISL. Assuming Gaussian channels, the maximum

Authorized licensed use limited to: NANJING UNIVERSITY OF AERONAUTICS AND ASTRONAUTICS. Downloaded on July 14,2025 at 01:09:40 UTC from IEEE Xplore. Restrictions apply.
                             © 2025 IEEE. All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. Personal use is permitted,
                                                but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
                             This article has been accepted for publication in IEEE Transactions on Network Science and Engineering. This is the author's version which has not been fully edited and
                                                        content may change prior to final publication. Citation information: DOI 10.1109/TNSE.2025.3585287


                                                                                                                                                                                                         5

                                                                                                                •     Satellite computing resources: we define the computing
                                                                                                                      resource occupancy W of the satellite after loading
                                                                                                                      the new DNN task slice as:
                                                                                                                                        W = q + mk , k ∈ {1, 2, ..., L},                                (4)
                                                                                                                      where q represents the computing resources cur-
                                                                                                                      rently occupied by the satellite for existing DNN task
                                                                                                                      slices, and mk represents the computing resources
                                                                                                                      required for each new DNN task slice. The maximum
                                                                                                                      computing resource capacity of the satellite is Mw . If
                                                                                                                      W < Mw , the task slices are loaded onto the satellite
                                                                                                                      for processing; otherwise, the respective task slice is
                                                                                                                      discarded.
                                                                                                                •     Satellite communication resources: we define the com-
                                                                                                                      munication resource occupancy U after satellite
                                                                                                                      transmission of intermediate data as follows:
                                  Fig. 2: System model.
                                                                                                                                          U = b + bk , k ∈ {1, 2, ..., L},                              (5)
                                                                                                                      where b represents the communication resources that
          achievable data rate r(i, j) for the transmission between                                                   the satellite is currently occupying. The maximum
          satellites i and j is [54]:                                                                                 communication resource capacity of the satellite is
                                    Pt Gi (j)Gj (i)Fi (j)Fj (i)                                                       Mb , bk represents the communication resources al-
                  r(i, j) = B log2 (1 +                         ),  (2)                                               located to each DNN task segment. If U < Mb , the
                                              kΘB                                                                     data can be transferred and the segment will proceed,
          where B is the bandwidth between satellites, Pt is the                                                      otherwise, the segment is discarded.
          transmission power, Gi (j) and Gj (i) are the gain of the
          transmit and received antennas, respectively. Fi (j), Fj (i)                                    3.4       Task Delay, Energy and Task Drop Model
          represent the beam pointing coefficient (Fi (j), Fj (i) < 1),
                                                                                                          The task delay comprises computational delay and trans-
          k is the Boltzmann constant, and Θ is the equivalent noise                                                                                        comp
                                                                                                          mission delay. For each pre-split DNN task, let qi,j,l denote
          temperature.
                                                                                                          the workload (computational data size) for slice l of j-th task
                                                                                                          in satellite i, and let Cxl represent the computing resources
          3.3   Computation Model                                                                         allocated by the satellite x which executes task slice l, where
                                                                                                                                     comp
          Each satellite is assumed to be equipped with a predefined                                      the computation delay ti,j,l is calculated by:
          DNN model, enabling it to handle specific DNN task seg-                                                                                        comp
                                                                                                                                                        qi,j,l
                                                                                                                                                comp
          ments. Additionally, a satellite can transmit its output to                                                                          ti,j,l =        .                                        (6)
                                                                                                                                                          Cxl
          adjacent satellites for further processing, such as inference
          and computations like pooling and convolution for the next                                          Let L be the expected sliced number, and NiTK
          slice. Given the constraints on satellite resource capacity and                                 be the number of DNN tasks in satellite i. The de-
                                                                                                                     comp comp                 comp
          the size of DNN task segments, optimizing the utilization of                                    lays {ti,j,1 , ti,j,2 , · · · , ti,j,L } are associated with the
          each satellite’s computing resources is crucial. This requires                                  slices of the j-th block processed by satellite i, while
          achieving a balanced workload distribution across satellites                                    {si,j,1 , si,j,2 , · · · , si,j,L } denote the satellites executing the
                                                                                                                                                                    comp
          for each DNN task segment. In this paper, we evaluate the                                       corresponding slices. The computation delay tx of satellite
          balance of workload distribution across the satellite network                                   x can be deduced by:
          using the variance of workload for each satellite as a metric.                                                                     Ni      TK
                                                                                                                                                L
          The variance function var is defined as:
                                                                                                                                                  tcomp
                                                                                                                                            XX  X
                             PL                                                                                              tcomp
                                                                                                                              x    =               i,j,k · Πsi,j,k =x ,                                 (7)
                                   (zk − z̄)2                                                                                               i∈S j=1 k=1
                     var = k=1                , k ∈ {1, 2, ..., L},    (3)
                                    L                                                                     where Πsi,j,k =x is a binary indicator function that takes the
          where zk represents the workload of each satellite, z̄ corre-                                   value 1 if si,j,k = x and 0 otherwise.
          sponds to the average workload across all satellites, and L                                         For the transmission delay, let MH(i, j) be the Manhattan
          specifies the expected sliced number.                                                           distance between satellite i and satellite j . MH(i, j) confines
             During the operation of a satellite network, critical sit-                                   satellite communications within a predefined maximum
          uations may occur when a satellite’s available computing                                        range, thereby simplifying path planning and bounding
                                                                                                                                                                       tran
          resources or communication resources approach exhaustion.                                       communication overhead to a predefined range. Let qi,j,k
          In both cases, the DNN mission segment assigned to the                                          denote the workload of intermediate data for slice k of j-th
          corresponding satellite cannot be processed, leading to the                                     task in satellite i. The transmission delay ttran
                                                                                                                                                         x of satellite x is
          potential loss of the original mission. For this reason, it is                                  calculated by:
          significant to determine whether the task can be processed                                                    Ni L−1  TK

          on the satellite based on the current computing resources
                                                                                                                       XX  X
                                                                                                                                                                    tran
                                                                                                            ttran
                                                                                                             x =                          MH(si,j,k , si,j,k+1 ) · qi,j,k · Πsi,j,k =x . (8)
          and communication resource usage.                                                                            i∈S j=1 k=1


Authorized licensed use limited to: NANJING UNIVERSITY OF AERONAUTICS AND ASTRONAUTICS. Downloaded on July 14,2025 at 01:09:40 UTC from IEEE Xplore. Restrictions apply.
                             © 2025 IEEE. All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. Personal use is permitted,
                                                but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
                               This article has been accepted for publication in IEEE Transactions on Network Science and Engineering. This is the author's version which has not been fully edited and
                                                          content may change prior to final publication. Citation information: DOI 10.1109/TNSE.2025.3585287


                                                                                                                                                                                                          6

                 The total delay tsum
                                  x of satellite x is defined as:                                           maximum allowable delay. Second, the total computational
                                                                                                            resources allocated to all scheduled DNN tasks must re-
                                      tsum  comp
                                       x = tx    + ttran
                                                    x .                                            (9)
                                                                                                            main within the available computational capacity of the
              Similarly, regarding the task energy consumption, we                                          current satellite (See Eq. 4). Similarly, the total commu-
          adopt the widely used model of energy consumption per                                             nication resources allocated to all scheduled DNN tasks
          computing cycle as e = κf 2 [41], where κ represents the                                          must not surpass the available communication capacity of
          energy consumption coefficient depending on the effective                                         the current satellite (See Eq. 5). Additionally, each satellite
          switching capacitance of the chip architecture and f denotes                                      must allocate a non-negative amount of computational and
          the CPU frequency (i.e., the computational capability of                                          communication resources to the DNN task associated with
                                                  comp
          satellite). So the energy consumption ei,j,l for slice l of j-th                                  it during time slot t. However, to reduce the service delay,
          task in satellite i is calculated by:                                                             it is undesirable to transmit tasks to satellites located far
                                                            2                                               away. So for any offloading scheme that aims to choose can-
                                      ecomp      l
                                       i,j,l = κCx dl cl ,                                       (10)       didate satellites si from the task offloading decision space
          where dl denotes the size of the computation data and cl                                          Ax determined by satellite x, the constraint is expressed
          indicates the task workload of slice l. This indicates that the                                   in Eq. 16a. The Manhattan distance between x and si ,
          slice l consists of dl bits, and its computational workload is                                    denoted as MH(x, si ), must be strictly less than DM , where
          cl cycles/bits.                                                                                   DM represents the maximum permissible communication
                     comp comp                comp
              Let {ei,j,1 , ei,j,2 , · · · , ei,j,L } be the energy consump-                                distance.
          tion of slices of j-th task of satellite i. The computation                                           Besides, the final offloading scheme is defined by a
                                     comp
          energy consumption ex of satellite x can be deduced by:                                           sequence of satellites (s1 , s2 , · · · , sL ), with each satellite
                                                                                                            assigned to execute its respective task segment. The arriving
                                             TK
                                      Ni L                                                                  tasks can either be completed according to a predefined
                                                       ecomp
                                     XX  X
                          ecomp
                           x    =                       i,j,k · Πsi,j,k =x .                     (11)       scheme (s1 , s2 , · · · , sL ) or be dropped during progressing.
                                     i∈S j=1 k=1                                                            The drop point dpi,j , which denotes the dropping point
             For the transmission energy consumption, let ps be the                                         of j-th task block for satellite i, is constrained to the set
          transmission power between satellites. The transmission                                           {1, 2, · · · , L} (See Eq. 16b). The offloading process is com-
          energy consumption etran  of satellite x is calculated by:                                        pleted when dpi,j = L + 1. From the perspective of DNN
                               x
                          TK
                                                                                                            partitioning, the number of DNN layers Nl must be strictly
                      Ni L−1
                     XX  X                                                                                  larger than a preset partitioned number L, as described in
                                                                  tran
          etran
           x =                     ps · MH(si,j,k , si,j,k+1 ) · qi,j,k · Πsi,j,k =x .                      Eq. 16c.
                     i∈S j=1 k=1
                                                                (12)
             The satellite x’s total energy consumption esum
                                                          x  can be                                         4 A N A DAPTIVE DNN PARTITIONING AND TASK
          expressed as the sum of two types of energy as:
                                                                                                            O FFLOADING F RAMEWORK
                                     esum  comp
                                      x = ex    + etran
                                                   x .                                           (13)       4.1      Framework Overview
              In addition, the task drop occurs when the computing                                          The offloading decisions are associated with the coupling
          or communication resources of the current satellite are in-                                       relationship among different variables. Even in the case of a
          sufficient to handle the assigned workload. Let Di be the                                         single-objective optimization problem, it remains a discrete
          number of drop of satellite i, the task total drop rate rD is                                     and non-convex problem, which is regarded as a classical
          calculated as:                 P                                                                  NP-hard problem [41]. To achieve the optimization objective
                                            Di
                                        i∈S                                                                 in Eq. 15, we propose an adaptive DNN partitioning and
                                 rD = P TK .                       (14)                                     task offloading framework APT-SAT, designed to enable col-
                                           Ni
                                                   i∈S                                                      laborative computing between multiple satellites. As shown
                                                                                                            in Fig. 3, this framework consists of three stages: the predic-
          3.5      Optimization Objective                                                                   tion stage, the partitioning stage, and the collaborative infer-
          Based on the aforementioned models, we aim to minimize                                            ence stage. Utilizing the proposed framework, the satellite
          the task drop rate, delay, and energy consumption during                                          distributes tasks into different blocks and splits them into
          the whole process. The optimization problem is defined                                            L segments at designated partition points. The cooperative
          below:                                                                                            processing sequence among satellites is determined by the
                                    X         X
                        min(rD +       tsum +   esum                                                        selected task offloading scheme, ensuring that each satellite
                                        i        i ),         (15)
                                              i∈S               i∈S                                         executes task processing based on the computed decision.
          s.t.                                                                                              The overview of these three stages is summarized below:
                               MH(x, si ) ≤ DM , ∀si ∈ Ax ,                                    (16a)            Prediction Stage: Using regression models, this stage es-
                                                                                                            timates layer-wise inference delay and energy consumption
             dpi,j ∈ {1, 2, · · · , L + 1},            ∀i ∈ S, 1 ≤ j ≤ NiTK ,                  (16b)        of DNNs. The obtained delay and energy prediction results
                                                                                                            are then used for the next DNN partitioning stage.
                            Nl ≥ L,          ∀i ∈ S, 1 ≤ j ≤ NiTK .                            (16c)
                                                                                                                Partition Stage: Introducing an adaptive DNN parti-
             Regarding the constraints, the following conditions must                                       tioning algorithm, this stage divides DNN computations
          be satisfied: First, the task delay must not exceed the                                           into several blocks. This algorithm considers various fac-
          designated QoS (Quality of Service) requirement for the                                           tors including satellite bandwidth, transmission power and

Authorized licensed use limited to: NANJING UNIVERSITY OF AERONAUTICS AND ASTRONAUTICS. Downloaded on July 14,2025 at 01:09:40 UTC from IEEE Xplore. Restrictions apply.
                               © 2025 IEEE. All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. Personal use is permitted,
                                                  but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
                             This article has been accepted for publication in IEEE Transactions on Network Science and Engineering. This is the author's version which has not been fully edited and
                                                        content may change prior to final publication. Citation information: DOI 10.1109/TNSE.2025.3585287


                                                                                                                                                                                                           7




                                                          Fig. 3: Overview of the proposed framework APT-SAT.


          satellite computing capacity to determine optimal partition                                     layer types. The equations are formulated as follows:
          points.                                                                                                                         X
              Collaborative Computing Stage: Offloading multiple                                                              yt = α0 +      αi xi                                                      (17)
                                                                                                                                                               ∀i
          DNN blocks to satellites for collaborative computing, this
          stage leverages a task offloading algorithm developed from                                                                                          X
                                                                                                                                            ye = β0 +               β i xi                              (18)
          SAC. Due to the presence of multiple satellites simultane-
                                                                                                                                                               ∀i
          ously collecting tasks from the ground, APT-SAT selects an
          appropriate offloading sequence for the satellites, ultimately                                  where α0 and β0 are intercept terms (constants), αi and βi
          reducing total inference delay and energy consumption,                                          are regression coefficients.
          increasing the task completion rate, and achieving work-                                            The prediction results will then serve as reference data
          load balancing across the computing resources of multiple                                       for the subsequent DNN partitioning stage.
          satellites.
                                                                                                          4.3      Partition Stage

          4.2   Prediction Stage                                                                          Algorithm 1 Adaptive DNN Partitioning Algorithm
          The primary goal of this stage is to analyze the inference la-                                  Input: wk , texec
                                                                                                                        k   , ttrans
                                                                                                                                k     , eexec
                                                                                                                                          k      , etrans
                                                                                                                                                    k     , L.
          tency and energy consumption of DNN layers within satel-                                        Output: The partitioning result with L − 1 points.
          lite environments. In this stage, we consider four distinct                                      1: Initialize all criteria and parameters, combinations of
          types of DNN layers: convolutional layers, fully connected                                          partition points CPP ← combinations(Nl , L − 1).
          layers, activation layers, and pooling layers.                                                   2: for i = 1, 2, · · · , |CPP| do
              It is worth noting that the analysis involves recording                                      3:     Calculate variance of workload VAR, total delay T
          the inference delay and energy consumption of individual                                            and total energy consumption E by:
                                                                                                                                  1
                                                                                                                             CPP                     Nl
          layer, rather than the entire model. Based on the analysis, we                                                      Pi                     P
                                                                                                              VAR ← var(            wk , · · · ,            wk )
          develop prediction models for each type of DNN layer using                                                                 k=1                  k=CPPL−1
                                                                                                                                                               i
          multiple linear regression (MLR)-based approach. Inspired                                                      CPP1                               Nl                    L−1
                                                                                                                            i
          by [19], [26], the independent variables in these models are                                                           texec                                texec              ttrans
                                                                                                                          P                                 P                      P
                                                                                                                 T ←              k    + ··· +                         k    +             CPPk i
          carefully selected based on the unique characteristics of each                                                  k=1                         k=CPPL−1
                                                                                                                                                           i
                                                                                                                                                                                  k=1
                                                                                                                             1
          layer type: For the convolution layer, the regression model                                                    CPP
                                                                                                                          Pi                                Nl                     L−1
                                                                                                                                 eexec                                eexec               etrans
                                                                                                                                                            P                       P
          uses the number of features in the input feature maps,                                                 E←               k    + ··· +                         k    +              CPPk    i
          and the term (filter size/stride)2 × (the number of filters), rep-
                                                                                                                          k=1                          k=CPPL−1
                                                                                                                                                            i
                                                                                                                                                                                   k=1

          resenting the computation per pixel in the input feature                                          4:    dvtotal ← θ · VAR + δ · T + ζ · E
          map. For fully-connected and pooling layers, the regression                                       5:    if dvtotal < dvmin then
          model relies on the sizes of the input and output feature                                                dvmin ← dvtotal
          maps. For activation layer, input data size is used in the                                               result ← CPPi
          regression model. Based on these feature variables xi , linear                                    6:    end if
                                                                                                            7: end for
          regression equations for predicting layer latency yt and
                                                                                                            8: return result
          energy consumption ye can be constructed for the four DNN

Authorized licensed use limited to: NANJING UNIVERSITY OF AERONAUTICS AND ASTRONAUTICS. Downloaded on July 14,2025 at 01:09:40 UTC from IEEE Xplore. Restrictions apply.
                             © 2025 IEEE. All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. Personal use is permitted,
                                                but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
                             This article has been accepted for publication in IEEE Transactions on Network Science and Engineering. This is the author's version which has not been fully edited and
                                                        content may change prior to final publication. Citation information: DOI 10.1109/TNSE.2025.3585287


                                                                                                                                                                                                           8

              In this stage, an adaptive DNN partitioning algorithm is                                    slices. However, the cumulative complexity remains O(Nl ).
          deployed to divide DNN computations into multiple blocks.                                       Therefore, the overall time complexity of Algorithm 1 is
          The algorithm is summarized in Algorithm 1. Let Nl repre-                                       O(Nl · Nl L−1 ), equivalently O(Nl L ). In terms of space
          sent the number of DNN layers. The inputs to the algorithm                                      complexity, the only additional memory required is for
          include the workload of each layer wk (k ∈ {1, 2, ..., Nl }),                                   storing the indicators of DNN layers, resulting in a space
          the execution time of each layer texec
                                               k  , the transmission time                                 complexity of O(Nl ). Furthermore, a multi-stage approach
          of each layer ttrans
                           k     , the execution energy consumption of                                    can be introduced to alleviate the computational complex-
          each layer eexec
                         k   , the transmission energy consumption of                                     ity when applying this algorithm to a large scale model.
          each layer etrans
                        k     , and expected sliced number L (L ≤ Nl ).                                   This approach initially partitions the network coarsely (e.g.,
          This algorithm traverses all DNN layers to obtain multiple                                      into large segments), followed by independent refinement
          partition points. During this search, computing the infer-                                      within each segment, effectively pruning the search space
          ence delay and energy consumption of each DNN block                                             while maintaining relatively high-quality solutions.
          is crucial for selecting partition points that minimize the
          overall delay and energy consumption of the collaborative
          computing stage. Furthermore, to ensure a balanced work-                                        4.4      Collaborative Computing Stage
          load among resource-constrained satellites, it is necessary
          to uniformly distribute the workload across task blocks to                                      After conducting Algorithm 1, the arriving DNN tasks are
          avoid overloading specific satellites and prevent others from                                   split into L segments and distributed into several blocks.
          being underutilized. This stage aims to minimize work-                                          Subsequently, it becomes necessary to establish a satellite
          load variance across subtasks during partitioning, enabling                                     processing sequence. In this stage, we propose a routing
          flexible offloading to satellites with heterogeneous resource                                   and task offloading algorithm that utilizes SAC due to
          capacities.                                                                                     its capability for continuous exploration and adaptive task
              As shown in Line 1 of Algorithm 1, the algorithm first                                      assignments. This adaptability is particularly valuable for
          initializes a set that contains all feasible Combinations of                                    effectively managing real-time fluctuations and uncertain-
          Partition Points (CPP) for partitioning DNN models. Each                                        ties in dynamic satellite networks.
          combination in the CPP set consists of unordered sequences                                          Since the offloading decision at the time slot t is influ-
          of partition points with a length of L − 1, generated through                                   enced by the decision at the previous time slot t − 1, the
          permutations and combinations. These sequences represent                                        computation offloading process in the assumed dynamic
          potential partitioning configurations for the models. For in-                                   scenario can be constructed as a Markov Decision Process
          stance, CPPL−1
                       i    denotes the (L−1)-th partition point of the i-                                (MDP). The MDP is defined as M = (S, A, P, R, γ), where
          th combination within CPP. By considering all possible com-                                     the elements S , A, P , R and γ represent the state space,
          binations, this step minimizes the time required to identify                                    action space, state transition matrix, reward function, and
          the optimal partition points. Additionally, variance (VAR) is                                   discount factor, respectively. Each element of the MDP is
          defined to quantify the workload balance of DNN blocks.                                         detailed as follows.
          Total delay T and energy consumption E are introduced                                               State space S : Each satellite is equipped with a prede-
          to comprehensively evaluate the influence of execution and                                      fined computational resource margin and a maximum com-
          transmission latency and energy consumption on the selec-                                       munication range referred to as the maximum interaction
          tion of partition points.                                                                       distance. At each time step t, the state st is constructed
              Then, our algorithm iterates all combinations of parti-                                     by combining two components: (i) a tensor ct1 , ct2 · · · , ctn ,
          tion points (Line 2 in Algorithm 1) to identify the optimal                                     representing the percentage of remaining computational
          partition points. For each combination, the DNN model is                                        resources of all satellites within the current satellite’s max-
          divided into several DNN blocks according to the specified                                      imum communication range, and (ii) the ratio wt , which
          partition points. The workload variance (Eq. 3), total latency                                  denotes the size of the current task slice relative to the
          (Eq. 9), and total energy consumption (Eq. 13) of these DNN                                     satellite’s maximum computational resource capacity. At
          blocks are calculated within the simulated satellite environ-                                   each time slot t, the state st can be defined as:
          ment. A weighted sum of these three metrics is then com-
          puted (Line 4 in Algorithm 1). The partition points yielding                                                                 st = {ct1 , ct2 , · · · , ctn , wt }.                            (19)
          the smallest combined metric value are selected as optimal.
          The final result, which includes the set of optimal partition                                       Action space A: After determining st , the corresponding
          points is returned. It is important to note that APT-SAT is                                     discrete and continuous actions are generated. The current
          primarily designed for targets DNN-based models such as                                         satellite is referred to as the central satellite, which can
          ResNet and VGG using horizontal partitioning; extending                                         select the next satellite to offload the arriving task slices.
          its applicability to other architectures requires additional                                    The potential candidates for offloading include all satellites
          modifications, such as modeling cross-layer dependencies                                        within the maximum communication range, as well as the
          for Transformer-based models.                                                                   central satellite itself if it chooses to continue executing the
              The time complexity of finding the optimal partition                                        next task slice locally. In the assumed satellite environments,
          point combination is dependent on the number of partition                                       the scale of the satellites is pre-defined, and a coordinate
          points, denoted as O(Nl L−1 ), where L − 1 represents the                                       system is established with the first satellite at the bottom-left
          number of partition points. For each partition combination,                                     corner as the reference point. The position of each satellite
          the time complexity of dividing the DNN model based                                             is represented in the form (xi , yi ). Consequently, the action
          on the partition points is determined by the size of the                                        space consists of the coordinates of all satellites within the

Authorized licensed use limited to: NANJING UNIVERSITY OF AERONAUTICS AND ASTRONAUTICS. Downloaded on July 14,2025 at 01:09:40 UTC from IEEE Xplore. Restrictions apply.
                             © 2025 IEEE. All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. Personal use is permitted,
                                                but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
                                This article has been accepted for publication in IEEE Transactions on Network Science and Engineering. This is the author's version which has not been fully edited and
                                                           content may change prior to final publication. Citation information: DOI 10.1109/TNSE.2025.3585287


                                                                                                                                                                                                              9

          maximum communication range. At each time slot t, the                                              Algorithm 2 Routing and Task Offloading Algorithm
          action at can be defined as:                                                                       Input: w, L, Sa , ssrc ⊂ Sa , π .
                       at = {(xt1 , y1t ), (xt2 , y2t ), · · · , (xtn , ynt )}.                   (20)       Output: The task offloading result scheme.
                                                                                                              1: Initialize scheme = [].
              In the action space, we assume that resource allocation is                                      2: while Length(scheme) < L do
          contingent upon the offloading decision, i.e., the offloading                                       3:     Calculate action space As for ssrc by Eq. 20
          decision takes precedence over resource allocation in the                                           4:     Obtain state S of satellites within ssrc ’s connection
          decision-making hierarchy. Therefore, due to the limited                                               by Eq. 19.
          computational resources available on satellites, there may                                          5:     Sample act A ∼ π(·|S; θ) based on S and As .
          be cases where the allocated resources are insufficient to                                          6:     The destination satellite sdst ← CalDst(A)
          execute the current task slice, rendering the action invalid.                                       7:     Available paths LP ← topk (DF S(ssrc , sdst )) ▷ top
          In such cases, the task will be dropped (See Eq. 14).                                                  k -shortest paths that can support the current task slice
              State Transition Probability Matrix P : The transition                                          8:     if LP is None then
          probability from state st to st+1 can be represented as                                             9:          Drop the task slice.
          q(st+1 |st , at ). Since st+1 is influenced by at and both the                                     10:          return scheme ← ∅
          state space s and the action space A are large, it is challeng-                                    11:     end if
          ing to accurately model q(st+1 |st , at ). Therefore, we adopt                                     12:     Select ls ← OptBW (LP) by Eq. 26.
          a model-free approach for computational offloading [55].                                           13:     Offload w to sdst via ls .
              Reward Function R: After performing action at under                                            14:     scheme ← task offloading result
          state st in time slot t, the system transitions to a new state                                     15:     Update the computational resource usage of
          st+1 and returns the corresponding reward rt . The reward                                              ssrc , sdst .
          function is designed to reflect the cost incurred during the                                       16:     for ∀i (satellite) traversed by ls do
          system state transition, which depends on both the objective                                       17:          Update the communication resources usage.
          function and the associated constraints. The reward function                                       18:     end for
          rt is defined as                                                                                   19: end while
                                                                                                             20: return scheme
                                 rt = ℜ − ϖOt − ρσ t − ϑ,                                         (21)
          where ℜ is a constant that ensures the reward tends to
          be positive. Ot represents the optimization objective (See                                         of intersections and the state. By evaluating the probability
          Eq. 15) in one time slot. ϖ and ρ are the scaling coefficient.                                     of each action being executed, the training process aims to
          σ t denotes the variance difference in the distribution of                                         maximize the overall state value V π (s), calculated as:
          resource states around the central satellite prior to and
                                                                                                                            V π (s) = Eπ (Qπ (st , at ) + αH(πt (·|st ))) ,                                (24)
          following action selection. ϑ is the penalty incurred during
          task offloading when the designated satellite lacks sufficient                                     where Qπ (st , at ) is the Q-function expressed by:
          computational resources to execute the current task slice,
          resulting in task failure.                                                                                 Qπ (st , at ) = Eπ (r(st , at , st+1 ) + γV π (st+1 )) .                              (25)
              We introduce an entropy-regularized reinforcement
                                                                                                                 The actor network outputs the probability of the avail-
          learning based on SAC to optimize task offloading deci-
                                                                                                             able actions as πθ (at |st ) and its respective entropy value as
          sions. In this structure, the agent receives a reward r at
                                                                                                             Hπ (at |st ).
          each time step t, which is proportional to the entropy of
                                                                                                                 Critic network Q: The critic network is designed to
          the policy at that time. The primary objective of SAC is to
                                                                                                             guide the correctness of the behavior. The critical Q-network
          not only optimize the cumulative expected rewards but also
                                                                                                             estimates the action value, while the target critic network
          the expected entropy of the policy as:
                                                                 !                                           indicates an estimation of the state value. To stabilize the
                                  X                                                                          training process, the target critic network is updated less
              π ∗ = arg max Eπ       r(st , at ) + αH(πt (·|st )) , (22)                                     frequently than the primary critic Q-network. Different from
                            π
                                           ∀t                                                                the actor networks, the output of the critic network is the
          where α is the parameter that determines the relative im-                                          value of Q function as q1 (st+1 , at ) and q2 (st+1 , at ).
          portance of the entropy term versus the reward. H(πt (·|st ))                                          Algorithm 2 outlines the procedure that leverages a well-
          is the entropy calculated by:                                                                      trained SAC policy network to facilitate offloading deci-
                                    X                                                                        sions. The inputs to the algorithm include the workload of
                  H(πt (·|st )) = −    πt (at |st ) log (πt (at |st )) . (23)                                one task segment w, the expected sliced number L, the set
                                                a                                                            of indices of available satellites Sa , the initial source satellite
              SAC utilizes double Q-networks and, during each up-                                            ssrc ⊂ Sa , the well-trained policy net π , and all parameters.
          date, selects the network that produces the smaller Q-value                                        The process begins by selecting ssrc from Sa to execute the
          to mitigate the issue of Q-value overestimation. A summary                                         first task slice of w. The offloading destination is determined
          of these networks is provided below:                                                               by π (See Eq. 22).
              Actor network µ: The actor network is responsible for                                              Then, ssrc computes the corresponding action space As
          exploring and selecting actions based on the learned policy,                                       by Eq. 20 (Line 3 in Algorithm 2). The state S is obtained
          which influences the agent’s behavior in the multi-agent                                           from the satellites in the action space As of ssrc (Line 4
          environment. The input includes the batch size, the number                                         in Algorithm 2). Subsequently, the algorithm uses the policy

Authorized licensed use limited to: NANJING UNIVERSITY OF AERONAUTICS AND ASTRONAUTICS. Downloaded on July 14,2025 at 01:09:40 UTC from IEEE Xplore. Restrictions apply.
                                © 2025 IEEE. All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. Personal use is permitted,
                                                    but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
                             This article has been accepted for publication in IEEE Transactions on Network Science and Engineering. This is the author's version which has not been fully edited and
                                                        content may change prior to final publication. Citation information: DOI 10.1109/TNSE.2025.3585287


                                                                                                                                                                                                         10
                                                                                                                                                    TABLE 3
          network π to dynamically select an action A from As (Line 5
                                                                                                                              M AIN EXPERIMENTAL PARAMETERS
          in Algorithm 2). Based on action A, it retrieves the corre-
          sponding destination satellite sdst (Line 6 in Algorithm 2).                                       Parameter                                                  Value
              In the satellite network, multiple paths may exist be-                                         Network topology N (size = N × N )                         4 ∼ 32
          tween ssrc and sdst , each with varying communication                                              Satellite bandwidth B                                      20 MHz [54]
                                                                                                             Satellite computation capability Cx (Ux )                  3 GHz [48]
          resource utilization status. In the routing process, the algo-                                     Satellite transmission power ps                            30 dBw [48]
          rithm initially employs depth-first search (DFS) to identify                                       Gateway bandwidth B0                                       10 MHz [48]
          all feasible transmission paths between ssrc and sdst . From                                       Effective capacitance coefficient κ                        10−28 [48]
                                                                                                             Size of computation data of tasks dl                       [200, 300] KB
          these candidate paths, the top k -shortest paths that can                                          Task workload cl                                           [2, 2.5] Kcycles/bit
          accommodate the current task slice are selected, forming                                           System time slot length τ                                  0.05
          the set LP (Line 7 in Algorithm 2). If no such paths exist,                                        Task arrival rate λ                                        4 ∼ 40
                                                                                                             Task splitting number L                                    3 (VGG19), 4 (ResNet101)
          the task is dropped, and an empty scheme is returned.                                              Maximum communication distance DM                          3 (VGG19), 3 (ResNet101)
          The optimal path is determined according to OptBW (LP)                                             Entropy weight α                                           0.01
          function defined as:                                                                               Reward correction factor ℜ                                 3
                                                                                                             Reward scaling coefficient ω, ρ                            1.5, 1
                                                                                                             Punishment factor ϑ                                        0.5
             OptBW (LP) = max{min(l1 ), min(l2 ), · · · , min(lk )}.
                                                                           (26)
                                                                                                                                            TABLE 4
               Here, {l1 , l2 , ..., lk } denotes the remaining available com-
                                                                                                                                D ETAILS OF SAC ARCHITECTURE
          munication resources allocated to the k paths in LP , where
          each path consists of multiple hops. The algorithm identifies                                       Net               Layer                             Units                      Activation
          the hop within each path with the minimum communication
                                                                                                                              Input                      State dimensions                         –
          resources, then selects the path ps corresponding to the hop                                                   Fully connected                        256                               –
                                                                                                             Actor
          with the highest resource availability among these minima.                                                     Fully connected                        256                               –
          This process ensures the identification of the optimal path                                                        Output                 Discrete action dimensions                 Softmax
          (Line 12 in Algorithm 2). The task slice is then offloaded via                                                      Input                State and Action dimensions                     –
                                                                                                                         Fully connected                       256                               ReLU
          ps , and the computational resources of ssrc and sdst , as well                                    Critic      Fully connected                       256                               ReLU
          as the communication resources in ps , are updated accord-                                                     Fully connected                       256                               ReLU
          ingly. In scenarios involving dynamic satellite topologies,                                                        Output                              1                                 –
          such as fluctuating resource availability or temporary vari-
          ations in ISL bandwidth, APT-SAT ’s SAC-based offloading
          algorithm reroutes tasks without requiring re-partitioning,                                     function applied to the output layer for discrete actions,
          thereby achieving offloading decisions promptly.                                                respectively, to ensure the bounds of the output actions. The
               The time complexity of the proposed task offloading                                        critic network comprises a three-layer fully connected struc-
          algorithm is primarily determined by the number of task                                         ture, where each layer is activated using the ReLU function
          slices L, the size of the available satellite set |Sa |, the com-                               to approximate the nonlinear Q value of the output. We
          putation of the top k paths between satellites, the number                                      implement two commonly used DNN models, ResNet101
          of orbits No in satellite network and the number of satellites                                  and VGG19 for performance validation. We verify the ef-
          Ns on an orbits. Besides, let Nisl denote the number of ISLs.                                   fectiveness of our proposed APT-SAT against the following
          So the overall complexity is O(L · (|Sa | + d + k · (|No · Ns | +                               four comparative baseline methods:
          |Nisl | + h))), where d is the number of satellites within the
          maximum communication distance, and h is the average                                                 •      Residual-Resource-Priority (RRP) selects the avail-
          hop count of paths.                                                                                         able satellites with the most residual computing re-
                                                                                                                      sources to process the next segment of the tasks [56].
                                                                                                               •      Random Offloading Location Assignment (ROLA)
          5     E XPERIMENTS                                                                                          is a method where the candidate satellite for task
          5.1   Experimental Setup                                                                                    offloading is independently and randomly selected.
                                                                                                               •      SCC is a self-adaptive task offloading method de-
          We develop a simulated satellite network environment and                                                    veloped from a genetic algorithm with the objective
          conduct extensive experiments to validate the effectiveness                                                 to minimize the task drop rate, delay and energy
          of the proposed APT-SAT. The experimental setup consists                                                    consumption [47].
          of a CPU-based server with 16 GB 4800-MHz DDR5, 2.50-                                                •      Deep Deterministic Policy Gradient (DDPG) is a
          GHz Intel Core i5.                                                                                          DDPG-based task offloading method with the ob-
              Considering the regularity of the satellite constellation                                               jective to minimize the system energy consumption
          topology (network size = N × N ), the neighbors of each                                                     subject to delay and resource constraints [48].
          satellite are defined as four adjacent satellites capable of
          direct communication. The task generated on each UE is                                              To ensure a fair comparison, we use the parameter con-
          subject to a Poisson distribution π(λ), where λ indicates                                       figurations specified in the original papers of the baseline
          the task arrival rate. Other main parameters used in the                                        methods. The effectiveness of each method is evaluated
          experiments are summarized in Table 3. The architectures                                        using the following four key metrics: task completion rate
          of the actor and critic networks used in SAC are shown in                                       (Eq. 14), total average delay (Eq. 9), total average energy
          Table 4. The actor network consists of two fully connected                                      consumption (Eq. 13), and the variance (Eq. 3) in the total
          layers designed to fit the behavior strategy, with a Softmax                                    workload assigned to each satellite.

Authorized licensed use limited to: NANJING UNIVERSITY OF AERONAUTICS AND ASTRONAUTICS. Downloaded on July 14,2025 at 01:09:40 UTC from IEEE Xplore. Restrictions apply.
                             © 2025 IEEE. All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. Personal use is permitted,
                                                but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
                             This article has been accepted for publication in IEEE Transactions on Network Science and Engineering. This is the author's version which has not been fully edited and
                                                        content may change prior to final publication. Citation information: DOI 10.1109/TNSE.2025.3585287


                                                                                                                                                                                                        11




                                       (a) Average delay                            (b) Energy consumption                          (c) Resource usage variance

                                Fig. 4: DNN partitioning performance achieved by different methods with ResNet101.




                                       (a) Average delay                            (b) Energy consumption                          (c) Resource usage variance

                                   Fig. 5: DNN partitioning performance achieved by different methods with VGG19.

                                                                         TABLE 5
                                                    TASK COMPLETION RATE WITH DIFFERENT NETWORK SCALES .
                                                                                                       Network Scale
                        Model            Method
                                                             16           64          144          256     400      576                   784          1024         6400         10000
                                         ROLA              62.5%        79.0%        76.0%        74.5%   73.1%    72.5%                 74.3%        71.9%        73.1%         72.6%
                                         RRP               55.7%        75.1%        72.4%        72.0%   67.9%    67.0%                 68.5%        68.4%        69.2%         68.6%
                        ResNet101
                                         DDPG              64.4%        77.4%        83.0%        80.8%   85.0%    83.3%                 83.8%        83.6%        83.8%         82.9%
                                         APT-SAT           66.5%        80.5%        84.5%        82.8% 87.4% 86.3%                      86.8%        86.3%        86.9%         87.2%
                                         ROLA              58.6%        70.1%        72.2%        69.8%   66.1%    66.5%                 66.8%        67.2%        67.5%         67.1%
                                         RRP               52.9%        72.9%        68.1%        66.2%   64.9%     64.7                 66.6%        64.4%        65.2%         65.7%
                        VGG19
                                         DDPG              62.8%        78.2%        77.0%        78.4%   77.5%    77.4%                 78.4%        76.4%        77.1%         77.5%
                                         APT-SAT           65.9%        82.8%        80.9%        81.5% 82.6% 83.9%                      82.0%        83.8%        83.4%         84.2%



          5.2   DNN Partitioning Performance                                                              catable resources vary across satellites, these methods may
                                                                                                          lead to increased computational and transmission delays,
          To investigate the impact of different DNN partitioning                                         as they lack the ability to achieve fine-grained control over
          methods on the experimental results, we compare the pro-                                        latency and energy consumption. EO-SAT, on the other
          posed APT-SAT against four baselines: EO-SAT, which of-                                         hand, does not partition tasks and directly offloads them
          floads DNN subtasks to a satellite node without partitioning                                    for execution. This approach results in significantly higher
          the model; RPT-SAT, which randomly selects partition-                                           computational latency, energy consumption, transmission
          ing points; SO-SAT, using single-point partitioning based                                       latency, and transmission energy consumption.
          on DNN slice execution latency and energy consumption;                                              Since the baseline methods do not inherently incorpo-
          and DO-SAT, employing dual-point partitioning under the                                         rate a DNN partitioning stage, the same DNN partitioning
          same criteria. Figs 4 and 5 show the average delay, energy                                      strategy used in APT-SAT is applied to these methods for
          consumption, and resource usage variance associated with                                        subsequent evaluations.
          each task under different task arrival rates. The results
          demonstrate that APT-SAT consistently achieves low de-
          lay and energy consumption while maintaining high re-                                           5.3      Overall Performance
          source usage by leveraging an adaptive DNN partitioning                                         We explore the impact of different task arrival rates while
          method. This method holistically considers the impact of                                        fixing the satellite scale to 10 × 10. The overall perfor-
          both task execution delay, energy and transmission delay,                                       mance of different methods, evaluated under two DNN
          energy on the collaborative computing stage. In contrast,                                       models ResNet101 and VGG19 is shown in Figs. 6 and 7.
          SO-SAT and DO-SAT adopt single-point and dual-point                                             Among them, Figs. 6(a) and 7(a) plot the task completion
          partitioning mechanisms, respectively. In complex satellite                                     rate performance, which shows a gradual decline as the
          network environments, especially when the currently allo-                                       task arrival rate increases. Specifically, APT-SAT exhibits

Authorized licensed use limited to: NANJING UNIVERSITY OF AERONAUTICS AND ASTRONAUTICS. Downloaded on July 14,2025 at 01:09:40 UTC from IEEE Xplore. Restrictions apply.
                             © 2025 IEEE. All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. Personal use is permitted,
                                                but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
                             This article has been accepted for publication in IEEE Transactions on Network Science and Engineering. This is the author's version which has not been fully edited and
                                                        content may change prior to final publication. Citation information: DOI 10.1109/TNSE.2025.3585287


                                                                                                                                                                                                        12




               (a) Task completion rate                         (b) Average delay                             (c) Energy consumption                         (d) Resource usage variance

                                         Fig. 6: Overall performance achieved by different methods with ResNet101.




               (a) Task completion rate                         (b) Average delay                             (c) Energy consumption                         (d) Resource usage variance

                                           Fig. 7: Overall performance achieved by different methods with VGG19.


          the capability to maintain relatively high performance, even                                    and DDPG, respectively. For the VGG19 model, APT-SAT
          under high task arrival rate conditions. This robustness                                        reduces the average delay by 360 ms, 150 ms, 80 ms, and
          can be attributed to its dynamic and adaptive action se-                                        40 ms, and the average energy consumption by 0.36 J, 0.22 J,
          lection mechanism combined with efficient path planning,                                        0.08 J, and 0.02 J against the same methods.
          which enables APT-SAT to explore a broader solution space.                                          Figs. 6(d) and 7(d) highlight the resource usage variance
          Consequently, it achieves approximately a 25% higher task                                       performance of different methods. In terms of the variance
          completion rate compared to alternative methods.                                                in satellite usage, A lower variance value of satellite usage
              Figs. 6(b)-(c) and Figs. 7(b)-(c) show the average delay                                    indicates a more robust consideration of load balancing
          and energy consumption comparison per task, respectively.                                       across different satellites. With the assistance of adaptive
          As task arrival rate increases, the resources available for task                                DNN partitioning (Line 3 in Algorithm 1) and reward
          offloading decrease, leading to a higher average number of                                      function configuration (See Eq. 21), APT-SAT effectively
          communication hops in the generated paths. This, in turn,                                       harnesses the available resources, i.e., APT-SAT can achieve
          leads to increased delays and energy consumption.                                               a similar performance compared with ROLA, which can
                                                                                                          theoretically achieve uniform distribution in resource allo-
               Among the evaluated methods, APT-SAT maintains
                                                                                                          cation.
          a relatively low delay and energy consumption perfor-
          mance by optimizing both transmission and computation
          delay/energy consumption during the routing and task                                            5.4      Impact of Network Scale
          offloading process. In contrast, RRP prefers to select the                                      We evaluate the task completion rate under varying network
          fittest satellites, leading to an imbalanced distribution where                                 scales, with the task arrival rate set to 40 to examine the
          a particular satellite is chosen by multiple decision-making                                    robustness of the proposed method under high task load
          satellites. For DDPG, owing to its insufficient exploration                                     conditions. As illustrated in Table 5, it is critical to accom-
          capability, it is unable to generate superior offloading de-                                    modate a heavy task load when the network scale is small
          cisions, and thus the delay and energy consumption are                                          (N = 4). However, with the increase of network scale, the
          increased when the task arrival rate is relatively high.                                        task completion rate increases significantly for all methods.
          Similarly, SCC struggles to adapt to dynamic network con-                                       Especially, the results demonstrate that APT-SAT can still
          ditions, further increasing delay and energy costs. ROLA,                                       outperform other methods even if the network scale is more
          relying on random selection within the action space, incurs                                     than 10,000, i.e., 100×100). This superior performance can
          substantial delays and energy usage due to its lack of                                          be attributed to APT-SAT’s capability to prioritize satellites
          strategic decision-making. In overall, for ResNet101 model,                                     that offer higher rewards, which indicates the selected satel-
          APT-SAT reduces the average delay by 330 ms, 170 ms,                                            lite has more available resources. Furthermore, APT-SAT
          100 ms, and 60 ms, and the average energy consumption by                                        effectively minimizes variance in the resource distribution
          0.43 J, 0.27 J, 0.15 J, and 0.07 J compared to RRP, ROLA, SCC,                                  among adjacent satellites before and after the offloading

Authorized licensed use limited to: NANJING UNIVERSITY OF AERONAUTICS AND ASTRONAUTICS. Downloaded on July 14,2025 at 01:09:40 UTC from IEEE Xplore. Restrictions apply.
                             © 2025 IEEE. All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. Personal use is permitted,
                                                but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
                             This article has been accepted for publication in IEEE Transactions on Network Science and Engineering. This is the author's version which has not been fully edited and
                                                        content may change prior to final publication. Citation information: DOI 10.1109/TNSE.2025.3585287


                                                                                                                                                                                                        13

          decision. These features collectively enable a more balanced                                    satellite characteristics, including inter-satellite interference
          task distribution and efficient offloading across the network.                                  and time-varying communication delays for interference
          When the network scale is 1,024, for ResNet101 model,                                           forecasts in the prediction stage.
          APT-SAT improves the task completion rate by 17.9%,
          14.3%, 5.1%, and 2.7% compared to RRP, ROLA, SCC, and
          DDPG, respectively. Similarly, for VGG19 model, APT-SAT                                         R EFERENCES
          achieves enhancements of 19.4%, 16.7%, 8.5%, and 7.5% over
                                                                                                          [1]  C.-X. Wang, X. You, X. Gao, X. Zhu, Z. Li, C. Zhang, H. Wang,
          RRP, ROLA, SCC, and DDPG, respectively.                                                              Y. Huang, Y. Chen, H. Haas, J. S. Thompson, E. G. Larsson, M. D.
                                                                                                               Renzo, W. Tong, P. Zhu, X. Shen, H. V. Poor, and L. Hanzo, “On the
                                                                                                               road to 6G: Visions, requirements, key technologies, and testbeds,”
          5.5    Parameter Sensitivity Analysis                                                                IEEE Communications Surveys & Tutorials, vol. 25, no. 2, pp. 905–
          Fig. 8 demonstrates the effect of ϖ and ρ in reward function                                         974, 2023.
                                                                                                          [2] Y. Gong, H. Yao, J. Wang, M. Li, and S. Guo, “Edge intelligence-
          rt (Eq. 21) on our proposed APT-SAT using ResNet101. It is                                           driven joint offloading and resource allocation for future 6G
          essential to analyze how variance affects the main reward                                            industrial Internet of Things,” IEEE Transactions on Network Science
          function by adjusting ρ while fixing the value of ϖ. The                                             and Engineering, vol. 11, no. 6, pp. 5644–5655, 2024.
          results show that neglecting the impact of variance (ρ = 0)                                     [3] Q. Zheng, J. Jin, Z. Shen, L. Wu, I. Ahmad, and Y. Xiang, “Dis-
                                                                                                               tributed task processing platform for infrastructure-less iot net-
          drastically worsens the performance. When ρ is close to ϖ,                                           works: A multi-dimensional optimisation approach,” IEEE Trans-
          the trend remains similar for all criteria. However, slightly                                        actions on Parallel and Distributed Systems, vol. 35, no. 12, pp. 2392–
          degraded performance in task completion ratio occurs for                                             2404, 2024.
                                                                                                          [4] G. Chen, S. Wu, Y. Deng, J. Jiao, and Q. Zhang, “VLEO satellite
          relatively high (= 1.5) or low (= 0.5) ρ values. To ensure
                                                                                                               constellation design for regional aviation and marine coverage,”
          balanced performance, we choose ϖ = 1.5 and ρ = 1 for                                                IEEE Transactions on Network Science and Engineering, vol. 11, no. 1,
          the main experiment.                                                                                 pp. 1188–1201, 2024.
                                                                                                          [5] Z. Shen, J. Jin, C. Tan, A. Tagami, S. Wang, Q. Li, Q. Zheng, and
                                                                                                               J. Yuan, “A survey of next-generation computing technologies in
                                                                                                               space-air-ground integrated networks,” ACM Computing Surveys,
                                                                                                               vol. 56, no. 1, 2023.
                                                                                                          [6] F. Wang, H. Yao, W. He, H. Chang, X. Xin, and S. Guo, “Time-
                                                                                                               sensitive scheduling mechanism based on end-to-end collabora-
                                                                                                               tive latency tolerance for low-earth-orbit satellite networks,” IEEE
                                                                                                               Transactions on Network Science and Engineering, vol. 11, no. 6,
                                                                                                               pp. 5149–5162, 2024.
                                                                                                          [7] Q. Tang, R. Xie, Z. Fang, T. Huang, T. Chen, R. Zhang, and F. R. Yu,
                                                                                                               “Joint service deployment and task scheduling for satellite edge
                                                                                                               computing: A two-timescale hierarchical approach,” IEEE Journal
                                                                                                               on Selected Areas in Communications, vol. 42, no. 5, pp. 1063–1079,
                                                                                                               2024.
                                                                                                          [8] X. Luo, D. Liu, H. Kong, S. Huai, H. Chen, and W. Liu, “You
                (a) Task completion rate              (b) Resource usage variance                              only search once: On lightweight differentiable architecture search
                                                                                                               for resource-constrained embedded platforms,” in Proceedings of
          Fig. 8: Overall performance of APT-SAT achieved with dif-                                            the ACM/IEEE Design Automation Conference (DAC), pp. 475–480,
                                                                                                               2022.
          ferent ρ values when ϖ=1.5                                                                      [9] T. Mohammed, C. Joe-Wong, R. Babbar, and M. D. Francesco,
                                                                                                               “Distributed inference acceleration with adaptive dnn partitioning
                                                                                                               and offloading,” in Proceedings of the IEEE Conference on Computer
                                                                                                               Communications (INFOCOM), pp. 854–863, 2020.
          6     C ONCLUSION                                                                               [10] L. Zeng, X. Chen, Z. Zhou, L. Yang, and J. Zhang, “CoEdge:
                                                                                                               Cooperative dnn inference with adaptive workload partitioning
          In this paper, we propose an adaptive DNN partitioning                                               over heterogeneous edge devices,” IEEE/ACM Transactions on Net-
          and task offloading framework APT-SAT within satellite                                               working, vol. 29, no. 2, pp. 595–608, 2021.
          computing environments. In this framework, we initially                                         [11] Y. Chen, Q. Zhang, Y. Zhang, X. Ma, and A. Zhou, “Energy and
                                                                                                               time-aware inference offloading for DNN-based applications in
          develop delay and energy consumption prediction models,                                              LEO satellites,” in Proceedings of the IEEE International Conference
          serving as the basis for DNN partitioning. Then, we develop                                          on Network Protocols (ICNP), pp. 1–6, 2023.
          an adaptive DNN partitioning algorithm leveraging delay                                         [12] S. Chen, Y.-C. Liang, S. Sun, S. Kang, W. Cheng, and M. Peng,
                                                                                                               “Vision, requirements, and technology trend of 6G: How to tackle
          and energy consumption predictions along with satellite
                                                                                                               the challenges of system coverage, capacity, user data-rate and
          resource distribution, enabling the division of correspond-                                          movement speed,” IEEE Wireless Communications, vol. 27, no. 2,
          ing DNN tasks into multiple segments. Finally, the tasks                                             pp. 218–228, 2020.
          collected by the satellites are split accordingly, and a rout-                                  [13] Y.-C. Tsai and C.-H. Lu, “Direct edge-to-edge attention-based
                                                                                                               multiple representation latent feature transfer learning,” IEEE
          ing and task offloading algorithm is utilized to determine                                           Transactions on Automation Science and Engineering, pp. 1–14, 2024.
          optimal offloading sequences for the task slices, after which                                   [14] Y. Zhou, R. Zhang, J. Liu, T. Huang, Q. Tang, and F. R. Yu,
          the tasks are executed. Experimental results show that our                                           “A hierarchical digital twin network for satellite communication
          proposed APT-SAT can outperform other methods across a                                               networks,” IEEE Communications Magazine, vol. 61, no. 11, pp. 104–
                                                                                                               110, 2023.
          range of metrics in diverse network scales and two DNN                                          [15] X. Zhang, J. Liu, R. Zhang, Y. Huang, J. Tong, N. Xin, L. Liu,
          models. Specifically, APT-SAT effectively minimizes task                                             and Z. Xiong, “Energy-efficient computation peer offloading in
          execution and transmission delay, as well as energy con-                                             satellite edge computing networks,” IEEE Transactions on Mobile
                                                                                                               Computing, vol. 23, no. 4, pp. 3077–3091, 2024.
          sumption, while maintaining a high task completion rate
                                                                                                          [16] H. H. Esmat, B. Lorenzo, and W. Shi, “Toward resilient network
          and ensuring efficient load balancing in satellite resource                                          slicing for satellite–terrestrial edge computing IoT,” IEEE Internet
          allocation. As a future work, we plan to integrate other                                             of Things Journal, vol. 10, no. 16, pp. 14621–14645, 2023.

Authorized licensed use limited to: NANJING UNIVERSITY OF AERONAUTICS AND ASTRONAUTICS. Downloaded on July 14,2025 at 01:09:40 UTC from IEEE Xplore. Restrictions apply.
                             © 2025 IEEE. All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. Personal use is permitted,
                                                but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
                              This article has been accepted for publication in IEEE Transactions on Network Science and Engineering. This is the author's version which has not been fully edited and
                                                         content may change prior to final publication. Citation information: DOI 10.1109/TNSE.2025.3585287


                                                                                                                                                                                                         14

          [17] W. Fan et al., “Joint DNN partition and resource allocation for                                  CNNs inference on board satellites: benchmarking with Myriad
               task offloading in edge–cloud-assisted IoT environments,” IEEE                                   2-based solution for the CloudScout case study,” Remote Sensing,
               Internet of Things Journal, vol. 10, no. 12, pp. 10146–10159, 2023.                              vol. 13, no. 8, p. 1518, 2021.
          [18] Z. Zhao, K. M. Barijough, and A. Gerstlauer, “DeepThings: Dis-                              [38] B. Denby and B. Lucia, “Orbital Edge Computing: Nanosatellite
               tributed adaptive deep learning inference on resource-constrained                                constellations as a new class of computer system,” in Proceedings of
               IoT edge clusters,” IEEE Transactions on Computer-Aided Design of                                the International Conference on Architectural Support for Programming
               Integrated Circuits and Systems, vol. 37, no. 11, pp. 2348–2359, 2018.                           Languages and Operating Systems, p. 939–954, 2020.
          [19] Y. Kang, J. Hauswald, C. Gao, A. Rovinski, T. Mudge, J. Mars, and                           [39] S. Wang and Q. Li, “Satellite computing: Vision and challenges,”
               L. Tang, “Neurosurgeon: Collaborative intelligence between the                                   IEEE Internet of Things Journal, vol. 10, no. 24, pp. 22514–22529,
               cloud and mobile edge,” ACM SIGARCH Computer Architecture                                        2023.
               News, vol. 45, no. 1, pp. 615–629, 2017.                                                    [40] L. Cheng et al., “Dynamic computation offloading in satellite edge
          [20] J. Mao, X. Chen, K. W. Nixon, C. Krieger, and Y. Chen, “MoDNN:                                   computing,” in Proceedings of the IEEE International Conference on
               Local distributed mobile computing system for deep neural net-                                   Communications (ICC), pp. 4721–4726, 2022.
               work,” in Proceedings of the Design, Automation & Test in Europe                            [41] Q. Tang, Z. Fei, B. Li, and Z. Han, “Computation offloading in
               Conference & Exhibition (DATE), pp. 1396–1401, 2017.                                             LEO satellite networks with hybrid cloud and edge computing,”
          [21] N. Shan, Z. Ye, and X. Cui, “Collaborative intelligence: Acceler-                                IEEE Internet of Things Journal, vol. 8, no. 11, pp. 9164–9176, 2021.
               ating deep neural network inference via device-edge synergy,”                               [42] Y. Zhang, H. Zhang, K. Sun, J. Huo, N. Wang, and V. C. Leung,
               Security and Communication Networks, vol. 2020, no. 1, p. 8831341,                               “Partial computation offloading in satellite-based three-tier cloud-
               2020.                                                                                            edge integration networks,” IEEE Transactions on Wireless Commu-
          [22] N. D. Lane, S. Bhattacharya, P. Georgiev, C. Forlivesi, L. Jiao,                                 nications, vol. 23, no. 2, pp. 836–847, 2023.
               L. Qendro, and F. Kawsar, “DeepX: A software accelerator for low-                           [43] B. Mao, F. Tang, Y. Kawamoto, and N. Kato, “Optimizing compu-
               power deep learning inference on mobile devices,” in Proceedings                                 tation offloading in satellite-UAV-served 6G IoT: A deep learning
               of the ACM/IEEE International Conference on Information Processing                               approach,” Ieee Network, vol. 35, no. 4, pp. 102–108, 2021.
               in Sensor Networks (IPSN), pp. 1–12, IEEE, 2016.                                            [44] Z. Ji, S. Wu, and C. Jiang, “Cooperative multi-agent deep reinforce-
          [23] L. Zhou, M. H. Samavatian, A. Bacha, S. Majumdar, and R. Teodor-                                 ment learning for computation offloading in digital twin satellite
               escu, “Adaptive parallel execution of deep neural networks on                                    edge networks,” IEEE Journal on Selected Areas in Communications,
               heterogeneous edge devices,” in Proceedings of the ACM/IEEE                                      vol. 41, no. 11, pp. 3414–3429, 2023.
               Symposium on Edge Computing, pp. 195–208, 2019.                                             [45] H. Li, J. Yu, L. Cao, Q. Zhang, Z. Song, and S. Hou, “Multi-
          [24] D. J. Pagliari, R. Chiaro, E. Macii, and M. Poncino, “CRIME: Input-                              agent reinforcement learning based computation offloading and
               dependent collaborative inference for recurrent neural networks,”                                resource allocation for leo satellite edge computing networks,”
               IEEE Transactions on Computers, vol. 70, no. 10, pp. 1626–1639, 2020.                            Computer Communications, vol. 222, pp. 268–276, 2024.
          [25] S. Zhang et al., “DeepSlicing: Collaborative and adaptive CNN                               [46] Y. Lyu, Z. Liu, R. Fan, C. Zhan, H. Hu, and J. An, “Optimal
               inference with low latency,” IEEE Transactions on Parallel and                                   computation offloading in collaborative LEO-IoT enabled MEC: A
               Distributed Systems, vol. 32, no. 9, pp. 2175–2187, 2021.                                        multiagent deep reinforcement learning approach,” IEEE Transac-
          [26] E. Li et al., “Edge AI: On-demand accelerating deep neural net-                                  tions on Green Communications and Networking, vol. 7, no. 2, pp. 996–
               work inference via edge computing,” IEEE Transactions on Wireless                                1011, 2022.
               Communications, vol. 19, no. 1, pp. 447–457, 2019.                                          [47] S. Peng, X. Hou, Z. Shen, Q. Zheng, J. Jin, A. Tagami, and J. Yuan,
                                                                                                                “Collaborative satellite computing through adaptive DNN task
          [27] H. Kim, J. S. Choi, J. Kim, and J. H. Ko, “A DNN partition-
                                                                                                                splitting and offloading,” in Proceedings of the IEEE Symposium on
               ing framework with controlled lossy mechanisms for edge-cloud
                                                                                                                Computers and Communications (ISCC), pp. 1–6, 2024.
               collaborative intelligence,” Future Generation Computer Systems,
                                                                                                           [48] H. Zhang, R. Liu, A. Kaushik, and X. Gao, “Satellite edge comput-
               vol. 154, pp. 426–439, 2024.
                                                                                                                ing with collaborative computation offloading: An intelligent deep
          [28] H. Li, X. Li, Q. Fan, Q. He, X. Wang, and V. C. M. Leung,
                                                                                                                deterministic policy gradient approach,” IEEE Internet of Things
               “Distributed DNN inference with fine-grained model partitioning
                                                                                                                Journal, vol. 10, no. 10, pp. 9092–9107, 2023.
               in mobile edge computing networks,” IEEE Transactions on Mobile
                                                                                                           [49] M. Jia, L. Zhang, J. Wu, Q. Guo, G. Zhang, and X. Gu, “Deep
               Computing, vol. 23, no. 10, pp. 9060–9074, 2024.
                                                                                                                multiagent reinforcement learning for task offloading and resource
          [29] Z. Liao, W. Hu, J. Huang, and J. Wang, “Joint multi-user DNN                                     allocation in satellite edge computing,” IEEE Internet of Things
               partitioning and task offloading in mobile edge computing,” Ad                                   Journal, vol. 12, no. 4, pp. 3832–3845, 2025.
               Hoc Networks, vol. 144, p. 103156, 2023.                                                    [50] Y. Zhang, H. Zhang, K. Sun, J. Huo, N. Wang, and V. C. M.
          [30] H. Liang, Q. Sang, C. Hu, D. Cheng, X. Zhou, D. Wang, W. Bao, and                                Leung, “Partial computation offloading in satellite-based three-tier
               Y. Wang, “DNN surgery: Accelerating DNN inference on the edge                                    cloud-edge integration networks,” IEEE Transactions on Wireless
               through layer partitioning,” IEEE Transactions on Cloud Computing,                               Communications, vol. 23, no. 2, pp. 836–847, 2024.
               vol. 11, no. 3, pp. 3111–3125, 2023.                                                        [51] Z. Ji, S. Wu, and C. Jiang, “Cooperative multi-agent deep reinforce-
          [31] N. Olsen, G. Albini, J. Bouffard, T. Parrinello, and L. Toffner-                                 ment learning for computation offloading in digital twin satellite
               Clausen, “Magnetic observations from CryoSat-2: calibration and                                  edge networks,” IEEE Journal on Selected Areas in Communications,
               processing of satellite platform magnetometer data,” Earth, Planets                              vol. 41, no. 11, pp. 3414–3429, 2023.
               and Space, vol. 72, no. 48, 2020.                                                           [52] H. Li, J. Yu, L. Cao, Q. Zhang, Z. Song, and S. Hou, “Multi-
          [32] B. Denby and B. Lucia, “Orbital edge computing: Nanosatellite                                    agent reinforcement learning based computation offloading and
               constellations as a new class of computer system,” in Proceedings of                             resource allocation for LEO satellite edge computing networks,”
               the International Conference on Architectural Support for Programming                            Computer Communications, vol. 222, pp. 268–276, 2024.
               Languages and Operating Systems (ASPLOS), pp. 939–954, 2020.                                [53] M. Ouyang, R. Zhang, B. Wang, J. Liu, T. Huang, L. Liu, J. Tong,
          [33] D. Bhattacherjee, S. Kassing, M. Licciardello, and A. Singla, “In-                               N. Xin, and F. R. Yu, “Network coding-based multipath transmis-
               orbit computing: An outlandish thought experiment?,” in Proceed-                                 sion for LEO satellite networks with domain cluster,” IEEE Internet
               ings of the ACM Workshop on Hot Topics in Networks, pp. 197–204,                                 of Things Journal, vol. 11, no. 12, pp. 21659–21673, 2024.
               2020.                                                                                       [54] I. Leyva-Mayorga, B. Soret, and P. Popovski, “Inter-plane inter-
          [34] S. Wang and Q. Li, “Satellite computing: Vision and challenges,”                                 satellite connectivity in dense LEO constellations,” IEEE Transac-
               IEEE Internet of Things Journal, vol. 10, no. 24, pp. 22514–22529,                               tions on Wireless Communications, vol. 20, no. 6, pp. 3430–3443, 2021.
               2023.                                                                                       [55] T. Ren, Z. Hu, J. Niu, W. Feng, and H. He, “M3OFF: Module-
          [35] P. Cassará, A. Gotta, M. Marchese, and F. Patrone, “Orbital edge                                compositional model-free computation offloading in multi-
               offloading on mega-LEO satellite constellations for equal access to                              environment MEC,” in Proceedings of the IEEE Conference on Com-
               computing,” IEEE Communications Magazine, vol. 60, no. 4, pp. 32–                                puter Communications (INFOCOM), pp. 2249–2258, 2024.
               36, 2022.                                                                                   [56] Y. Zhang, C. Chen, L. Liu, D. Lan, H. Jiang, and S. Wan,
          [36] Z. Lai, Q. Wu, H. Li, M. Lv, and J. Wu, “Orbitcast: Exploiting mega-                             “Aerial edge computing on orbit: A task offloading and allocation
               constellations for low-latency earth observation,” in Proceedings of                             scheme,” IEEE Transactions on Network Science and Engineering,
               the International Conference on Network Protocols (ICNP), pp. 1–12,                              vol. 10, no. 1, pp. 275–285, 2023.
               IEEE, 2021.
          [37] E. Rapuano, G. Meoni, T. Pacini, G. Dinelli, G. Furano, G. Giuf-
               frida, and L. Fanucci, “An FPGA-based hardware accelerator for


Authorized licensed use limited to: NANJING UNIVERSITY OF AERONAUTICS AND ASTRONAUTICS. Downloaded on July 14,2025 at 01:09:40 UTC from IEEE Xplore. Restrictions apply.
                              © 2025 IEEE. All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. Personal use is permitted,
                                                 but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
